[BASIC]
# you can change llm_endpoint to ollama or openai. For OpenAI, you will need to enter your openai_api_key. For Ollama, you will need run 'ollama serve' then 'ollama run (llm_model)' to download the model.
llm_endpoint = ollama
llm_model = openhermes

[OPENAI_CONFIG]
openai_model = gpt-4
openai_engine = text-davinci-002
openai_max_tokens = 4000

[CREWAI_SCRIPTS]
llm_endpoint_within_generated_scripts = ollama
llm_model_within_generated_scripts = openhermes
add_api_keys_to_crewai_scripts = y
add_ollama_host_url_to_crewai_scripts = y

[AUTHENTICATORS]
openai_api_key = 
ngrok_auth_token = 
ngrok_api_key = 

[REMOTE_HOST_CONFIG]
reset_ollama_host_on_startup = n
use_remote_ollama_host = n
name_of_remote_ollama_host = ngrok

[MISCELLANEOUS]
# on_screen_loggin_level can be DEBUG, INFO, WARNING, ERROR, CRITICAL.
# However, a complete debug log is also saved to autocrew.log, and is overwritten each time the program is run. 
on_screen_logging_level = INFO
